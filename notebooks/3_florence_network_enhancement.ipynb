{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hurricane Florence Graph Object Generation\n",
    "\n",
    "The following code was used to create the graph object for Hurricane Florence, and is modified from the Harvey notebooks.\n",
    "\n",
    "Note that two blocks use Django DB calls and therefore must be run on the correct database. These are commented out here, as they were run on a different machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialisation ###\n",
    "import os\n",
    "\n",
    "# Location of data files\n",
    "DIR = './data/florence_user_location/'\n",
    "GEXF_FILE = 'Florence_network_data_20210720.gexf' # All components of network of class=2 users detected within 7 days of event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import yaml\n",
    "import googlemaps\n",
    "\n",
    "def parse_coordinates(string):\n",
    "    '''Parse a string for coordinates'''\n",
    "    reg = '[nsewNSEW]?\\s?-?\\d+[\\.°]\\s?\\d+°?\\s?[nsewNSEW]?'\n",
    "    result = re.findall(reg, string)\n",
    "    # Check if format is degrees minutes rather than degrees decimal (discard seconds)\n",
    "    reg_has_minutes = '\\d+\\s?°\\s*\\d+.?\\d+\\s?\\''\n",
    "    has_minutes = re.findall(reg_has_minutes, string)\n",
    "    if len(result) == 2: # Coordinates detected\n",
    "        for i in range(len(result)):\n",
    "            # Replace middle degree symbol with decimal:\n",
    "            reg_middle_degree = '(\\d+)°\\s?(\\d+)'\n",
    "            result[i] = re.sub(reg_middle_degree, r'\\1.\\2', result[i])\n",
    "            # Remove trailing degree symbol, N and E marks:\n",
    "            reg_strip = '[°neNE\\s]'\n",
    "            result[i] = re.sub(reg_strip, '', result[i])\n",
    "            # Replace south/west with negative sign:\n",
    "            reg_replace_sw = '[swSW](\\d+\\.\\d+)|(\\d+\\.\\d+)[swSW]'\n",
    "            result[i] = re.sub(reg_replace_sw, r'-\\1\\2', result[i])\n",
    "            # Remove double negative (where string contained eg. '-99.10w')\n",
    "            result[i] = re.sub('--', '-', result[i])\n",
    "            result[i] = float(result[i])\n",
    "            # Convert minutes to decimal\n",
    "            if len(has_minutes) == 2:\n",
    "                result[i] = math.modf(result[i])[1] + math.modf(result[i])[0] / 60 * 100\n",
    "                result[i] = round(result[i], 5)\n",
    "        return (result[0], result[1])\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_in_bounding_box(coords, boxes):\n",
    "    '''\n",
    "    Check whether coordinates fall within defined bounding box:\n",
    "    Boxes are defined as their NW and SE points.\n",
    "    '''\n",
    "    for box in boxes:\n",
    "        if coords[0] < box[0][0] and coords[0] > box[1][0]:\n",
    "            if coords[1] > box[0][1] and coords[1] < box[1][1]:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_local(location, boxes, known_localities=[]):\n",
    "    '''\n",
    "    Check whether a location string falls within a set of \n",
    "    bounding boxes using Googlemaps API.\n",
    "    \n",
    "    <<<< WARNING >>>>\n",
    "    If a broad location is given (e.g. 'Texas', 'USA'), the \n",
    "    returned coordinates may fall within the bounding box by\n",
    "    chance and give false positives.\n",
    "    '''\n",
    "    if not location:\n",
    "        return\n",
    "    # Check known localities first to save on API requests:\n",
    "    for x in known_localities:\n",
    "        if x in location:\n",
    "            return True\n",
    "    coords = get_coords(location)\n",
    "    if coords:\n",
    "        return(is_in_bounding_box(coords, boxes))\n",
    "    return\n",
    "\n",
    "def get_coords(location):\n",
    "    if not location:\n",
    "        return\n",
    "    # Try and parse coordinates from string rather than API query:\n",
    "    coords = parse_coordinates(location)\n",
    "    # Get coords from API:\n",
    "    if not coords:\n",
    "        with open(\"auth.yml\", 'r') as ymlfile:\n",
    "            auth = yaml.load(ymlfile, Loader=yaml.BaseLoader)\n",
    "        key = auth['apikeys']['googlemaps2']\n",
    "        gmaps = googlemaps.Client(key=key)\n",
    "        geocode_result = gmaps.geocode(location)\n",
    "        if geocode_result:\n",
    "            lat = geocode_result[0]['geometry']['location']['lat']\n",
    "            lon = geocode_result[0]['geometry']['location']['lng']\n",
    "            coords = (lat, lon)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of profile location strings based on users who are part of the\n",
    "# largest connected component (based on existing gexf file exported from\n",
    "# website interface)\n",
    "# Note -- users limited to those appearing in first week of event.\n",
    "\n",
    "from streamcollect.models import User, Event, Tweet \n",
    "import networkx as nx\n",
    "\n",
    "G = nx.read_gexf(DIR + GEXF_FILE)\n",
    "Gcc = sorted(nx.connected_components(G.to_undirected()), key=len, reverse=True)        \n",
    "G = G.subgraph(Gcc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Event name mismatch -- check database set in Django",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f4d1ff1ec97a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Confirm correct database is set in Django settings.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'Florence'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEVENT_NAME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Event name mismatch -- check database set in Django'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0muser_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Event name mismatch -- check database set in Django"
     ]
    }
   ],
   "source": [
    "# NOTE: run on correct database\n",
    "\n",
    "# Confirm correct database is set in Django settings.py\n",
    "EVENT_NAME = Event.objects.all()[0].name.replace(' ', '')\n",
    "if 'Florence' not in EVENT_NAME:\n",
    "    raise Exception('Event name mismatch -- check database set in Django')\n",
    "    \n",
    "user_ids = list(G.nodes)\n",
    "locs = User.objects.filter(user_id__in=user_ids\n",
    "                          ).filter(location__isnull=False\n",
    "                          ).exclude(location=''\n",
    "                          ).values_list('location', flat=True)\n",
    "\n",
    "locs = [l.lower().strip() for l in locs] \n",
    "locs = set(locs)\n",
    "\n",
    "with open(DIR + 'flr_locs.txt', 'w') as file:\n",
    "\tfile.write(json.dumps(list(locs))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running get_coords() for 29507 strings...\n",
      "Requesting 1000 of 29507\n",
      "Requesting 2000 of 29507\n",
      "Requesting 3000 of 29507\n",
      "Requesting 4000 of 29507\n",
      "Requesting 5000 of 29507\n",
      "Requesting 6000 of 29507\n",
      "Requesting 7000 of 29507\n",
      "Requesting 8000 of 29507\n",
      "Requesting 9000 of 29507\n",
      "Requesting 10000 of 29507\n",
      "Requesting 11000 of 29507\n",
      "Requesting 12000 of 29507\n",
      "Requesting 13000 of 29507\n",
      "Requesting 14000 of 29507\n",
      "Requesting 15000 of 29507\n",
      "Requesting 16000 of 29507\n",
      "Requesting 17000 of 29507\n",
      "Requesting 18000 of 29507\n",
      "Requesting 19000 of 29507\n",
      "Requesting 20000 of 29507\n",
      "Requesting 21000 of 29507\n",
      "Requesting 22000 of 29507\n",
      "Requesting 23000 of 29507\n",
      "Requesting 24000 of 29507\n",
      "Requesting 25000 of 29507\n",
      "Requesting 26000 of 29507\n",
      "Requesting 27000 of 29507\n",
      "Requesting 28000 of 29507\n",
      "Requesting 29000 of 29507\n"
     ]
    }
   ],
   "source": [
    "# Running again after disruption, skipping where vals already recorded\n",
    "\n",
    "LOCALITY_COORDS_DICT_FILE = \"locality_coords_dict_flr_v2.txt\"\n",
    "\n",
    "with open(DIR + 'flr_locs.txt') as json_file:\n",
    "    locs = json.load(json_file)\n",
    "print('Running get_coords() for {} strings...'.format(len(locs)))\n",
    "\n",
    "try:\n",
    "    with open(DIR + LOCALITY_COORDS_DICT_FILE) as file:\n",
    "        loc_coords_dict = json.load(file)\n",
    "except:\n",
    "    loc_coords_dict = {}\n",
    "\n",
    "c = 0\n",
    "for loc in locs:\n",
    "    c += 1\n",
    "    if c%1000 == 0:\n",
    "        print('Requesting {} of {}'.format(c, len(locs)))\n",
    "    try:\n",
    "        loc_coords_dict[loc]\n",
    "    except:\n",
    "        loc_coords_dict[loc] = get_coords(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCALITY_COORDS_DICT_FILE = \"locality_coords_dict_flr_v3.txt\"\n",
    "\n",
    "with open(DIR + LOCALITY_COORDS_DICT_FILE, 'w') as file:\n",
    "     file.write(json.dumps(loc_coords_dict)) # use `json.loads` to do the reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Data is not yet adjusted to exclude the exclusion box.\n",
    "# 36.4134, -75.1782     Top Right\n",
    "# 31.7161, -81.4328     Bottom left\n",
    "# 34.9624, -78.2680     Middle Point for exclusion \n",
    "\n",
    "boxes = [[(36.4134, -81.4328), (31.7161, -75.1782)]]\n",
    "# Boxes with exclusion:\n",
    "# boxes = [[(34.9624, -81.4328), (31.7161, -78.2680)],  # Top Left, Bottom Middle\n",
    "#         [(36.4134, -78.2680), (31.7161, -75.1782)]]   # Top Middle, Bottom right\n",
    "\n",
    "loc_dict = {}\n",
    "for k, v in loc_coords_dict.items():\n",
    "    try:\n",
    "        loc_dict[k] = is_in_bounding_box(v, boxes)\n",
    "    except:\n",
    "        loc_dict[k] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCALITY_DICT_FILE = \"locality_dict_flr.txt\"\n",
    "\n",
    "with open(DIR + LOCALITY_DICT_FILE, 'w') as file:\n",
    "     file.write(json.dumps(loc_dict)) # use `json.loads` to do the reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Event name mismatch -- check database set in Django",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e3a98f560bdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mEVENT_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'Florence'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEVENT_NAME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Event name mismatch -- check database set in Django'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstreamcollect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Event name mismatch -- check database set in Django"
     ]
    }
   ],
   "source": [
    "# # NOTE: run on correct database\n",
    "\n",
    "# Confirm correct database is set in Django settings.py\n",
    "EVENT_NAME = Event.objects.all()[0].name.replace(' ', '')\n",
    "if 'Florence' not in EVENT_NAME:\n",
    "    raise Exception('Event name mismatch -- check database set in Django')\n",
    "\n",
    "from streamcollect.models import User, Event, Tweet \n",
    "import networkx as nx\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "GEXF_FILE = 'Florence_network_data_20210720.gexf'\n",
    "LOCALITY_DICT_FILE = \"locality_dict_flr.txt\"\n",
    "\n",
    "with open(DIR + LOCALITY_DICT_FILE) as json_file:\n",
    "    loc_dict = json.load(json_file)\n",
    "\n",
    "G = nx.read_gexf(DIR + GEXF_FILE)\n",
    "Gcc = sorted(nx.connected_components(G.to_undirected()), key=len, reverse=True)        \n",
    "G = G.subgraph(Gcc[0])\n",
    "\n",
    "usd = User.objects.filter(user_id__in=G.nodes).values('user_id', 'location')\n",
    "loc_dict_db = {}\n",
    "for x in usd:\n",
    "    if x['location']:\n",
    "        loc_dict_db[x['user_id']] = x['location'].lower().strip()\n",
    "    else:\n",
    "        loc_dict_db[x['user_id']] = None\n",
    "\n",
    "loc_prf_db = {}\n",
    "for n in G.nodes:\n",
    "    if loc_dict_db[int(n)] == None:\n",
    "        continue\n",
    "    if loc_dict[loc_dict_db[int(n)]] == None:\n",
    "        continue\n",
    "    loc_prf_db[n] = {'lcl_profile': loc_dict[loc_dict_db[int(n)]]}\n",
    "\n",
    "nx.set_node_attributes(G, loc_prf_db)\n",
    "\n",
    "\n",
    "filename = ‘Florence_network_data_' + datetime.today().strftime('%Y%m%d') + '.gexf'\n",
    "nx.write_gexf(G, filename, prettyprint=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
